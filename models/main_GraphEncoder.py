import os
import time
from pathlib import Path

import numpy as np
import soundfile as sf
import torch
import torch.nn as nn
import torch.nn.functional as F
import torch.optim as optim
from torch.utils.data import DataLoader
from torch.utils.tensorboard import SummaryWriter
from tqdm import tqdm
from tqdm.contrib import tenumerate

# æ—¢å­˜ã®è©•ä¾¡ã‚¹ã‚¯ãƒªãƒ—ãƒˆã‚’ã‚¤ãƒ³ãƒãƒ¼ãƒˆ
# from All_evaluation import main as evaluation
# ä¿®æ­£æ¸ˆã¿ãƒ‡ãƒ¼ã‚¿ãƒ­ãƒ¼ãƒ€ãƒ¼ã‚’ã‚¤ãƒ³ãƒãƒ¼ãƒˆ
from CsvDataset import ReverbEncoderDataset, CsvInferenceDataset
# è£œåŠ©æå¤±è¨ˆç®—ç”¨ã®ãƒ˜ãƒ«ãƒ‘ãƒ¼ã‚’ã‚¤ãƒ³ãƒãƒ¼ãƒˆ
from mymodule import my_func, const, LossFunction, confirmation_GPU
from models.graph_utils import GraphConfig, NodeSelectionType, EdgeSelectionType


from models.Graph_Encoder import ReverbGNNEncoder

# CUDAã®å¯ç”¨æ€§ã‚’ãƒã‚§ãƒƒã‚¯
device = confirmation_GPU.get_device()
print(f"Using device: {device}")


def padding_tensor(tensor1, tensor2):
	"""
	æœ€å¾Œã®æ¬¡å…ƒï¼ˆä¾‹: æ™‚ç³»åˆ—é•·ï¼‰ãŒç•°ãªã‚‹2ã¤ã®ãƒ†ãƒ³ã‚½ãƒ«ã«å¯¾ã—ã¦ã€
	çŸ­ã„æ–¹ã‚’æœ«å°¾ã«ã‚¼ãƒ­ãƒ‘ãƒ‡ã‚£ãƒ³ã‚°ã—ã¦é•·ã•ã‚’ãã‚ãˆã‚‹ã€‚
	"""
	len1 = tensor1.size(-1)
	len2 = tensor2.size(-1)
	max_len = max(len1, len2)

	pad1 = [0, max_len - len1]
	pad2 = [0, max_len - len2]

	padded_tensor1 = F.pad(tensor1, pad1)
	padded_tensor2 = F.pad(tensor2, pad2)

	return padded_tensor1, padded_tensor2


def train(model: nn.Module,
          train_csv: str,
          val_csv: str,
          wave_type: str,
          reverb_loss_weight: float = 0.1,  # â˜…è¿½åŠ : è£œåŠ©æå¤±ã®é‡ã¿ (Î±)
          out_path: str = "./RESULT/pth/result.pth",
          main_loss_type: str = "SISDR",  # â˜…å¤‰æ›´: main_loss_type ã«åç§°å¤‰æ›´
          batchsize: int = const.BATCHSIZE,
          checkpoint_path: str = None,
          train_count: int = const.EPOCH,
          earlystopping_threshold: int = 5):
	"""å­¦ç¿’é–¢æ•° (ãƒãƒ«ãƒã‚¿ã‚¹ã‚¯å­¦ç¿’å¯¾å¿œ)
	Args:
		model (nn.Module): å­¦ç¿’ã•ã›ã‚‹ãƒ¢ãƒ‡ãƒ« (ReverbGNNEncoder)
		reverb_feature_columns (list): æ•™å¸«æ®‹éŸ¿ç‰¹å¾´é‡ã¨ã—ã¦ä½¿ç”¨ã™ã‚‹CSVã®åˆ—åãƒªã‚¹ãƒˆ
		reverb_loss_weight (float): è£œåŠ©æå¤±ã®é‡ã¿ Î±
		main_loss_type (str): ä¸»æå¤±é–¢æ•°ã®ç¨®é¡ ("stft_MSE", "L1", "MSE", "SISDR")
        // ... (ãã®ä»–çœç•¥)
	"""

	"""GPUã®è¨­å®š"""
	device = confirmation_GPU.get_device()

	""" ãã®ä»–ã®è¨­å®š """
	out_path = Path(out_path)
	out_name, out_dir = out_path.stem, out_path.parent
	writer = SummaryWriter(log_dir=f"{const.LOG_DIR}\\{out_name}")

	now = my_func.get_now_time()
	csv_path = os.path.join(const.LOG_DIR, out_name, f"{out_name}_{now}.csv")
	my_func.make_dir(csv_path)
	with open(csv_path, "w") as csv_file:
		csv_file.write(
			f"dataset,out_name,main_loss_func,reverb_loss_weight\n{train_csv},{out_path},{main_loss_type},{reverb_loss_weight}\n")
		csv_file.write("epoch,total_loss,main_loss,reverb_loss\n")  # ãƒ­ã‚°ãƒ˜ãƒƒãƒ€ãƒ¼ã‚’ä¿®æ­£

	""" Early_Stoppingã®è¨­å®š """
	best_loss = np.inf
	earlystopping_count = 0

	""" Load dataset ãƒ‡ãƒ¼ã‚¿ã‚»ãƒƒãƒˆã®èª­ã¿è¾¼ã¿ (â˜…reverb_feature_columnsã‚’è¿½åŠ ) """
	train_dataset = ReverbEncoderDataset(csv_path=train_csv, input_column_header=wave_type)
	train_loader = DataLoader(dataset=train_dataset, batch_size=batchsize, shuffle=True,
	                          pin_memory=True, collate_fn=ReverbEncoderDataset.collate_fn)

	val_dataset = ReverbEncoderDataset(csv_path=val_csv, input_column_header=wave_type)
	val_loader = DataLoader(dataset=val_dataset, batch_size=batchsize, shuffle=True,
	                        pin_memory=True, collate_fn=ReverbEncoderDataset.collate_fn)

	""" æœ€é©åŒ–é–¢æ•°ã®è¨­å®š """
	optimizer = optim.Adam(model.parameters(), lr=0.001)

	# ä¸»æå¤± (å¼·èª¿éŸ³å£°ã®å“è³ª)
	main_loss_func = LossFunction.get_loss_computer(main_loss_type, device)
	# è£œåŠ©æå¤± (æ®‹éŸ¿ç‰¹å¾´é‡ã®ç²¾åº¦) - æ¨™æº–ã®MSEã‚’ä½¿ç”¨
	reverb_loss_func = nn.MSELoss().to(device)

	""" ãƒã‚§ãƒƒã‚¯ãƒã‚¤ãƒ³ãƒˆã®è¨­å®š (æ—¢å­˜ãƒ­ã‚¸ãƒƒã‚¯ã¯çœç•¥) """
	# ... (å¿…è¦ã«å¿œã˜ã¦å®Ÿè£…)

	""" å­¦ç¿’ã®è¨­å®šã‚’å‡ºåŠ› (æ—¢å­˜ãƒ­ã‚¸ãƒƒã‚¯ã¯çœç•¥) """
	# ...

	my_func.make_dir(out_dir)
	model.train()

	start_time = time.time()
	for epoch in range(1, train_count + 1):
		print(f"Train Epoch: {epoch}")
		total_loss_sum = 0
		main_loss_sum = 0
		reverb_loss_sum = 0

		# â˜…å¤‰æ›´: dataloaderã‹ã‚‰3ã¤ã®è¦ç´ ã‚’ã‚¢ãƒ³ãƒ‘ãƒƒã‚¯
		for _, (mix_data, target_data, reverb_true) in tenumerate(train_loader):

			# â˜…å¤‰æ›´: reverb_true ã‚’GPUã«ç§»å‹•
			mix_data, target_data, reverb_true = mix_data.to(device), target_data.to(device), reverb_true.to(device)

			optimizer.zero_grad()

			mix_data = mix_data.to(torch.float32)
			target_data = target_data.to(torch.float32)

			# â˜…å¤‰æ›´: ãƒ¢ãƒ‡ãƒ«ã‹ã‚‰2ã¤ã®å‡ºåŠ›ã‚’å–å¾—
			estimate_data_w, reverb_pred = model(mix_data)

			# ãƒ‡ãƒ¼ã‚¿ã®æ•´å½¢
			estimate_data_w, target_data = padding_tensor(estimate_data_w, target_data)

			# ãƒ¢ãƒ‡ãƒ«ã®å‡ºåŠ› (waveform) ã«ãƒãƒ£ãƒ³ãƒãƒ«æ¬¡å…ƒãŒãªã„å ´åˆã«è¿½åŠ  (é€šå¸¸ [B, 1, L] ãŒå¿…è¦)
			if estimate_data_w.ndim == 2:
				estimate_data_w = estimate_data_w.unsqueeze(1)

			# --- æå¤±ã®è¨ˆç®— ---
			# 1. ä¸»æå¤± (å¼·èª¿éŸ³å£°)
			L_main = main_loss_func(estimate_data_w, target_data)

			# 2. è£œåŠ©æå¤± (æ®‹éŸ¿ç‰¹å¾´é‡)
			L_reverb = reverb_loss_func(reverb_pred, reverb_true)

			# 3. ç·æå¤±
			model_loss = L_main + reverb_loss_weight * L_reverb

			# --- æå¤±ã®é›†è¨ˆ ---
			total_loss_sum += model_loss.item()
			main_loss_sum += L_main.item()
			reverb_loss_sum += L_reverb.item() * reverb_loss_weight  # é‡ã¿ã‚’æ›ã‘ãŸå¾Œã®å€¤ã‚’é›†è¨ˆ

			""" å¾Œå‡¦ç† """
			model_loss.backward()
			optimizer.step()

			del mix_data, target_data, reverb_true, estimate_data_w, reverb_pred, model_loss
			torch.cuda.empty_cache()

		# --- ã‚¨ãƒãƒƒã‚¯é›†è¨ˆã¨ãƒ­ã‚° ---
		avg_total_loss = total_loss_sum / len(train_loader)
		avg_main_loss = main_loss_sum / len(train_loader)
		avg_reverb_loss = reverb_loss_sum / len(train_loader)

		# ãƒã‚§ãƒƒã‚¯ãƒã‚¤ãƒ³ãƒˆã®ä½œæˆ (æ—¢å­˜ãƒ­ã‚¸ãƒƒã‚¯ã¯çœç•¥)
		torch.save({
			"epoch": epoch,
			"model_state_dict": model.state_dict(),
			"optimizer_state_dict": optimizer.state_dict(),
			"loss": avg_total_loss,  # ç·æå¤±ã‚’ä¿å­˜
		}, f"{out_dir}/{out_name}_ckp.pth")

		writer.add_scalar(f'total_loss', avg_total_loss, epoch)
		writer.add_scalar(f'L_main', avg_main_loss, epoch)
		writer.add_scalar(f'L_reverb', avg_reverb_loss, epoch)

		print(f"[{epoch}] Total Loss: {avg_total_loss:.6f}, Main Loss: {avg_main_loss:.6f}, Reverb Loss: {avg_reverb_loss:.6f}")

		torch.cuda.empty_cache()
		with open(csv_path, "a") as out_file:
			out_file.write(f"{epoch},{avg_total_loss},{avg_main_loss},{avg_reverb_loss}\n")

		""" Early_Stopping ã®åˆ¤æ–­ (æ—¢å­˜ãƒ­ã‚¸ãƒƒã‚¯ã‚’ç·æå¤±ã§å®Ÿè¡Œ) """
		model.eval()
		val_total_loss = 0.0

		with torch.no_grad():
			progress_bar_val = tqdm(val_loader, desc="Validation")
			# â˜…å¤‰æ›´: dataloaderã‹ã‚‰3ã¤ã®è¦ç´ ã‚’ã‚¢ãƒ³ãƒ‘ãƒƒã‚¯
			for mix_data, target_data, reverb_true in progress_bar_val:
				mix_data, target_data, reverb_true = mix_data.to(device), target_data.to(device), reverb_true.to(device)

				estimate_data_w, reverb_pred = model(mix_data)
				estimate_data_w, target_data = padding_tensor(estimate_data_w, target_data)
				if estimate_data_w.ndim == 2:
					estimate_data_w = estimate_data_w.unsqueeze(1)

				L_main = main_loss_func(estimate_data_w, target_data)
				L_reverb = reverb_loss_func(reverb_pred, reverb_true)
				model_loss = L_main + reverb_loss_weight * L_reverb

				val_total_loss += model_loss.item()
				progress_bar_val.set_postfix({"loss": model_loss.item()})

			avg_val_loss = val_total_loss / len(val_loader)

		if avg_val_loss < best_loss:
			print(f"Validation loss improved ({best_loss:.6f} --> {avg_val_loss:.6f}). Saving model...")
			best_loss = avg_val_loss
			torch.save(model.state_dict(), f"{out_dir}/BEST_{out_name}.pth")
			earlystopping_count = 0
		else:
			earlystopping_count += 1
			print(f"Validation loss did not improve. Patience: {earlystopping_count}/{earlystopping_threshold}")

		if earlystopping_count >= earlystopping_threshold:
			print("Early stopping triggered. Training finished.")
			break

	torch.save(model.to(device).state_dict(), f"{out_dir}/{out_name}_{epoch}.pth")

	""" å­¦ç¿’ãƒ¢ãƒ‡ãƒ«(pthãƒ•ã‚¡ã‚¤ãƒ«)ã®å‡ºåŠ› (æ—¢å­˜ãƒ­ã‚¸ãƒƒã‚¯ã¯çœç•¥) """
	# ...
	writer.close()

	""" å­¦ç¿’æ™‚é–“ã®è¨ˆç®— (æ—¢å­˜ãƒ­ã‚¸ãƒƒã‚¯ã¯çœç•¥) """
	time_end = time.time()  # ç¾åœ¨æ™‚é–“ã®å–å¾—
	time_sec = time_end - start_time  # çµŒéæ™‚é–“ã®è¨ˆç®—(sec)
	time_h = float(time_sec) / 3600.0  # sec->hour
	print(f"timeï¼š{str(time_h)}h")  # å‡ºåŠ›


def test(model: nn.Module, test_csv: str, wave_type: str, out_dir: str, model_path: str, prm: int = const.SR):
	"""
	æ¨è«–é–¢æ•° (å¼·èª¿éŸ³å£°ã®ã¿ã‚’å‡ºåŠ›)
	"""
	# ãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒªã‚’ä½œæˆ
	my_func.make_dir(out_dir)
	model_path = Path(model_path)
	model_dir, model_name = model_path.parent, model_path.stem

	# ãƒ¢ãƒ‡ãƒ«ã®ãƒ­ãƒ¼ãƒ‰
	model.load_state_dict(torch.load(os.path.join(model_dir, f"BEST_{model_name}.pth"), map_location=device))
	model.eval()

	# CsvInferenceDataset ã¯æ³¢å½¢ã¨ãƒ•ã‚¡ã‚¤ãƒ«åã®ã¿ã‚’è¿”ã™ãŸã‚ã€reverb_feature_columns ã¯ä¸è¦
	dataset = CsvInferenceDataset(csv_path=test_csv, input_column_header=wave_type)
	dataset_loader = DataLoader(dataset, batch_size=1, shuffle=False, pin_memory=True)  # æ¨è«–ã¯shuffle=FalseãŒä¸€èˆ¬çš„

	for mix_data, mix_name in tqdm(dataset_loader):
		mix_data = mix_data.to(device).to(torch.float32)

		# â˜…å¤‰æ›´: ãƒ¢ãƒ‡ãƒ«ã‹ã‚‰å¼·èª¿éŸ³å£° (estimate_data_w) ã®ã¿ã‚’å–å¾— (reverb_pred ã¯ç ´æ£„)
		with torch.no_grad():
			estimate_data_w, _ = model(mix_data)

		separate = estimate_data_w.cpu().squeeze().detach().numpy()

		# æ­£è¦åŒ– (æ—¢å­˜ãƒ­ã‚¸ãƒƒã‚¯)
		mix_max = torch.max(mix_data).cpu().detach().numpy()
		if np.max(np.abs(separate)) > 1e-8:  # ã‚¼ãƒ­é™¤ç®—é˜²æ­¢
			data_to_write = separate / np.max(np.abs(separate)) * mix_max
		else:
			data_to_write = separate  # å…¨ã¦0ã®å ´åˆã¯ãã®ã¾ã¾

		# ä¿å­˜
		out_path = os.path.join(out_dir, (mix_name[0] + ".wav"))
		sf.write(out_path, data_to_write, prm)
		torch.cuda.empty_cache()


if __name__ == "__main__":
	# --- å­¦ç¿’å®Ÿè¡Œè¨­å®š ---
	num_mic = 1
	num_node = 16
	model_type = "ReverbGNNEncoder"  # æ–°ã—ã„ãƒ¢ãƒ‡ãƒ«å
	gnn_type = "GCN"
	wave_type = "noise_reverb_path"  # CSVã®å…¥åŠ›ã‚«ãƒ©ãƒ å

	# â˜…è£œåŠ©ã‚¿ã‚¹ã‚¯è¨­å®š (é‡è¦)
	# CsvDataset.pyã§å®šç¾©ã—ãŸã‚«ãƒ©ãƒ åã¨ä¸€è‡´ã•ã›ã‚‹
	reverb_cols = ["cepstrum_coeffs", "rt60", "c50", "d50"]
	# ç·ç‰¹å¾´æ¬¡å…ƒ = ã‚±ãƒ—ã‚¹ãƒˆãƒ©ãƒ (16) + RT60(1) + C50(1) + D50(1) = 19
	reverb_dim = 19
	reverb_loss_weight = 0.1  # è£œåŠ©æå¤±ã®é‡ã¿ Î±

	# ğŸš¨ ãƒ‘ã‚¹ã®è¨­å®š ğŸš¨
	# const.MIX_DATA_DIR ãŒé©åˆ‡ã«è¨­å®šã•ã‚Œã¦ã„ã‚‹ã“ã¨ã‚’å‰æã¨ã—ã¾ã™ã€‚
	# ã“ã“ã§ã¯ã€CSVã¨å‡ºåŠ›ã®ãƒ™ãƒ¼ã‚¹ãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒªã‚’ä»®å®šã—ã¾ã™ã€‚
	dir_name = "reverb_encoder"
	train_csv_path = f"{const.MIX_DATA_DIR}/{dir_name}/mix_wav/train.csv"
	val_csv_path = f"{const.MIX_DATA_DIR}/{dir_name}/mix_wav/val.csv"
	test_csv_path = f"{const.MIX_DATA_DIR}/{dir_name}/mix_wav/test.csv"

	# --- ãƒ¢ãƒ‡ãƒ«åˆæœŸåŒ– ---
	# GraphConfigã¯å¿…è¦ã«å¿œã˜ã¦èª¿æ•´ã—ã¦ãã ã•ã„
	graph_config = GraphConfig(
		num_edges=num_node,
		node_selection=NodeSelectionType.ALL,
		edge_selection=EdgeSelectionType.KNN,
		bidirectional=True,
	)

	model = ReverbGNNEncoder(
		n_channels=num_mic,
		n_classes=1,
		num_node=num_node,
		gnn_type=gnn_type,
		graph_config=graph_config,
		reverb_feature_dim=reverb_dim  # ç‰¹å¾´é‡æ¬¡å…ƒã‚’æ¸¡ã™
	).to(device)

	# --- å­¦ç¿’ã®å®Ÿè¡Œ ---
	out_name = f"{model_type}_{gnn_type}_alpha{reverb_loss_weight}_node{num_node}"

	train(
		model=model,
		train_csv=train_csv_path,
		val_csv=val_csv_path,
		wave_type=wave_type,
	    reverb_loss_weight=reverb_loss_weight, # â˜…è¿½åŠ 
		out_path=f"{const.PTH_DIR}/{dir_name}/{model_type}/{out_name}.pth",
		main_loss_type="SISDR",
		batchsize=4, checkpoint_path=None, train_count=500, earlystopping_threshold=10
	)

	# --- æ¨è«–ã®å®Ÿè¡Œ ---
	test_out_dir = f"{const.OUTPUT_WAV_DIR}/{dir_name}/{model_type}/{out_name}"
	test(
		model=model,
		test_csv=test_csv_path,
		wave_type=wave_type,
		out_dir=test_out_dir,
		model_path=f"{const.PTH_DIR}/{dir_name}/{model_type}/{out_name}.pth"
	)

	# --- è©•ä¾¡ã®å®Ÿè¡Œ ---
	# evaluation(
	# 	target_dir=f"path/to/your/{dir_name}/test/clean", # ã‚¯ãƒªãƒ¼ãƒ³éŸ³å£°ã®ãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒªã‚’æŒ‡ã™ã‚ˆã†ã«ä¿®æ­£
	# 	estimation_dir=test_out_dir,
	# 	out_path=f"{const.EVALUATION_DIR}/{dir_name}/{model_type}/{out_name}.csv",
	# )

	print("--- ã‚¹ã‚¯ãƒªãƒ—ãƒˆç”Ÿæˆå®Œäº† ---")
	print("ğŸš¨ å®Ÿè¡Œå‰ã«ã€ãƒ¢ãƒ‡ãƒ«ãƒ•ã‚¡ã‚¤ãƒ«ã®ã‚¤ãƒ³ãƒãƒ¼ãƒˆã€CSV/ãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒªãƒ‘ã‚¹ã€ãã—ã¦ `const.py` ã®ãƒ‘ã‚¹è¨­å®šã‚’ç¢ºèªã—ã¦ãã ã•ã„ã€‚")