GNNを用いた音源強調モデルのグラフ構築を自動化する最初のアイデアとして、「**特徴量学習の深化とマルチタスクグラフ構築**」の詳細をご提案します。

このアプローチは、モデルの中間層で**残響特性に特化した特徴量**を学習させ、その類似度を基にグラフのエッジ重みを動的に決定するものです。また、補助的な学習目標を追加することで、モデルがより正確な音響的コンテキストを捉えられるように誘導します。

---

## アイデア 1: 特徴量学習の深化とマルチタスクグラフ構築

### 1. 目的

従来のランダムな接続や、固定的な中間特徴の類似度に基づくグラフ構築から脱却します。代わりに、モデルが入力信号から**残響特性**を学習し、その学習した特性の類似度によってグラフのエッジ重みを決定することで、音響空間の物理的・音響的コンテキストを反映した、より**意味のあるグラフ構造を動的に生成**することを目指します。

### 2. モデル構造の変更：残響特徴量抽出エンコーダの導入

モデルのU-Net構造の中間層に、「残響特性を専門的に抽出するエンコーダ」を挿入します。

| 項目 | 詳細 | 検討箇所 |
| :--- | :--- | :--- |
| **主要モデル** | `UGNN`系（時間領域）または`SpeqGNN`系（周波数領域）。 | - |
| **エンコーダの役割** | 入力信号から、音響空間の特性を示す**コンパクトな残響特徴量**（例: ケプストラム係数、RT60、C50/D50）を抽出する。 | - |
| **エンコーダ構造** | CNNとRNN/LSTMを組み合わせた構造が効果的です。CNNで局所的な音響特徴を捉えた後、RNNで残響の**時間的減衰の連続性**や変動パターンを学習させます。 | 既存の`ConvTasNet_models.py`や`wave_unet.py`のConvブロックを参考に設計します。 |
| **挿入位置** | **GNN層への入力直前**：このエンコーダの出力が、後のセクションで述べるエッジ重みの計算に利用されます。 | - |

---

### 3. 動的なエッジ重みの決定

モデルが学習した残響特徴量を用いて、ノード間の接続の強さ（エッジ重み）を計算します。これにより、同じ音響空間に属するノードが強く結びつくことが期待されます。

| 項目 | 詳細 | 実装への影響 |
| :--- | :--- | :--- |
| **特徴量の入力** | `models/graph_utils.py`内の`GraphBuilder`クラスのロジックを拡張し、KNNの類似度計算に**学習された残響特徴量**（$\mathbf{Z}$）を使用します。 | `models/graph_utils.py`内の`_select_edges_knn`メソッドを修正します。 |
| **類似度計算** | 2つのノードの残響特徴量 ($\mathbf{z}_i$ と $\mathbf{z}_j$) 間の**コサイン類似度**などを計算し、その値をエッジ重み $w_{ij}$ とします。 | $w_{ij} = \text{CosineSimilarity}(\mathbf{z}_i, \mathbf{z}_j)$ |
| **グラフ接続の確定** | 計算された類似度 $w_{ij}$ の値が**高い順**に、設定されたエッジ数 $K$（`graph_config.num_edges`）だけエッジを残します。 | - |
| **GNNへの適用** | 最終的に残ったエッジに対して、この類似度 $w_{ij}$ をGNN層（特に**GAT層**）の`edge_weight`引数に渡し、**情報伝達の重み**として利用します。 | `models/GNN.py`のGAT層の利用を検討します。 |

---

### 4. マルチタスク学習（補助損失）の導入

残響特徴量抽出エンコーダが「真の」残響特性を学習するように強制するため、通常の音源強調損失に加えて、補助的な学習目標を導入します。

| 項目 | 詳細 | 検討箇所 |
| :--- | :--- | :--- |
| **損失の定義** | 総損失 $L_{\text{total}} = L_{\text{main}} + \alpha \cdot L_{\text{reverb}}$ | $\alpha$: 損失バランスを調整するハイパーパラメータ。 |
| **主損失 ($L_{\text{main}}$)** | モデルの最終出力（強調後の波形/スペクトログラム）とクリーン信号との損失（例: SI-SDR, MSE）。 | `mymodule/LossFunction.py`に定義されている損失関数を利用します。 |
| **補助損失 ($L_{\text{reverb}}$)** | **残響特徴量エンコーダの出力** $\mathbf{Z}$ と、教師IRから事前に抽出した**正解の残響特徴量** $\mathbf{Z}_{true}$ との間の距離（例: $\text{MSE}$ や $\text{L1}$ 損失）。 | $L_{\text{reverb}} = \text{MSE}(\mathbf{Z}, \mathbf{Z}_{true})$。 |
| **データセットの準備** | `Dataset/generate_reveb_dataset.py`の処理を拡張し、生成される学習データに**真の残響特徴量**（例: ケプストラム係数）を教師信号 $\mathbf{Z}_{true}$ として含めます。 | - |

このマルチタスク学習により、モデルは「残響を正確に表現する」という中間目標を達成するように訓練され、結果として、その特徴量に基づくグラフ構造の**音響的妥当性**が担保されます。